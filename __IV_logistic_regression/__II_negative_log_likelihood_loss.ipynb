{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II Logistic regression loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a look how we compute the loos function for the logistic regression model the so called <code>**negative log-likelihood loss**</code>. To recap main aspects from previous section lets bring some expressions about logistic regression.\n",
    "\n",
    "\\begin{multline*}\n",
    "h(x) = \\sigma(w^{\\top} x + b)\n",
    "\\end{multline*}\n",
    "\n",
    "Here the <code>**h stand for hypothesis**</code> is just our activation function output\n",
    "\n",
    "\\begin{multline*}\n",
    "h(x) = a\n",
    "\\end{multline*}\n",
    "\n",
    "We  <code>**compute**</code>  te posterior probabilities as:\n",
    "\n",
    "\\begin{multline*}\n",
    "P(y | x) = \n",
    "\\begin{Bmatrix}\n",
    "h(x) & \\text{if} \\ y = 1 \\\\\n",
    "1 - h(x) & \\text{if} \\ y = 0\n",
    "\\end{Bmatrix}\n",
    "\\end{multline*}\n",
    "\n",
    "For binary class problem (0 and 1) we  <code>**want**</code>  these probabilities to be:\n",
    "\n",
    "\\begin{multline*}\n",
    "P (y = 0 |x ) \\approx 1 \\ \\text{if} \\ y = 0\n",
    "\\end{multline*}\n",
    "\\begin{multline*}\n",
    "P (y = 1 |x ) = 1 - P (y = 0 |x )  \\approx 1 \\ \\text{if} \\ y = 1\n",
    "\\end{multline*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically two things are going on here, it is how we <code>**compute**</code> this probability and what we <code>**want**</code> this probability to be.  Let take a look at what we want. So we want this  on the left hand side probability of the class membership for class 0 to be 1, to be maximized if the true label is indeed 0. And vice versa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to maximize the probability for the given true label and how is this probability computed ? So again this class membership probability for y equals 1 by just the activation so it just simply the activation which is logistic sigmoid applied to the net input:\n",
    "\n",
    "\\begin{multline*}\n",
    "P (y = 1 |\\vec{x})  = h(x) \n",
    "\\end{multline*}\n",
    "\n",
    "And for the second case can be compute by 1 minuse the activation.\n",
    "\n",
    "\\begin{multline*}\n",
    "P (y = 0 |\\vec{x})  = 1 - h(x) \n",
    "\\end{multline*}\n",
    "\n",
    "Lets rewrite this piecewise function how we compute this class membership using <code>**compact notation**</code>:\n",
    "\n",
    "\\begin{multline*}\n",
    "P (y |x)  = a^y(1-a)^{(1 - y)}\n",
    "\\end{multline*}\n",
    "\n",
    "This essentially summarizes this piecewise function in one equation. And that works pretty simply just try to plug in the class membership, either 1 or 0 and look what you are left with. \n",
    "\n",
    "\\begin{multline*}\n",
    "P (y = 1|\\vec{x})  = a^1(1-a)^{(1 - 1)} = a^1(1-a)^{0} = a^1 1 = a\n",
    "\\end{multline*}\n",
    "\n",
    "\\begin{multline*}\n",
    "P (y = 0|\\vec{x})  = a^0(1-a)^{(1 - 0)} = 1(1-a)^{1} = 1-a\n",
    "\\end{multline*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually we dont have one single data point in data set for multiple training examples we want to maximize class membership probabilites for all these examples in training set by finding <code>**good and optimal parameters**</code> that our probabilties depend on:\n",
    "\n",
    "\\begin{multline*}\n",
    "P (y^{[i]}, ...,y^{[n]}  |x^{[1]}, ..., x^{[n]})  = \\prod^{n}_{i=1} P(y^{[i]} | x^{[i]})\n",
    "\\end{multline*}\n",
    "\n",
    "You might remember this as <code>**[Maximum Likelihood Estimation](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation)**</code> from other statistics classes. We want to maximize the likelihood of the probability of observing te data given the model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood loss\n",
    "\n",
    "\n",
    "\n",
    "\\begin{multline*}\n",
    "L(\\mathbf{w}) = P(\\mathbf{y} | \\mathbf{x};\\mathbf{w})\n",
    "\\end{multline*}\n",
    "\\begin{multline*}\n",
    " = \\prod^{n}_{i=1} P(y^{(i)} | x^{(i)}; \\mathbf{w})\n",
    "\\end{multline*}\n",
    "\\begin{multline*}\n",
    " = \\prod^{n}_{i=1} (\\sigma(z^{(i)}))^{y^{(i)}} (1-\\sigma(z^{(i)}))^{1 - y^{(i)}}\n",
    "\\end{multline*}\n",
    "\n",
    "In practice it is easier to maximize the (natural) log of this equation which is called the log-likelihood function <code>**by doing this we can replace the product with a sum**</code>:\n",
    "\n",
    "\\begin{multline*}\n",
    "l(\\mathbf{w}) = log \\mathbf{L} (\\mathbf{w})\n",
    "\\end{multline*}\n",
    "\\begin{multline*}\n",
    "= \\sum^{n}_{i = 1} [y^{(i)} log(\\sigma(z^{(i)})) + (1 - y^{(i)})log(1 - \\sigma(z^{(i)}))]\n",
    "\\end{multline*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And numerically on the computer this is just more stable to implement it is more stable when we use gradient descent. But you can think of it also as maximizing the log likelihood also maximizes the likelihood. It kind of like one thing, if we maximze one thing we maxizime the other this is why we can do that. Though it is not quite the log likelihood because there is one more modification. In practice also we have stochastic gradient descent and in it we want to <code>**minimize**</code> so it is more convenient to <code>**minimize negative log likelihood instead of maximizing log-likelihood**</code>\n",
    "\n",
    "\\begin{multline*}\n",
    "\\mathcal{L} = -\\mathcal{l}(\\mathbf{w})\n",
    "\\end{multline*}\n",
    "\\begin{multline*}\n",
    "= - \\sum^{n}_{i = 1} [y^{(i)} log(\\sigma(z^{(i)})) + (1 - y^{(i)})log(1 - \\sigma(z^{(i)}))]\n",
    "\\end{multline*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in a way if for gradient descent we would give a log likelihood function as the loss function to optimize then it would actually maximize this loos and would get very small calss membership probabilities for the correct labels. So turn around this problem instead of maximizing the log likelihood we can minimize the negative log likelihood just by putting a negative sign in front. And we turn this maximization problem in minimization problem and then we can use without trouble Stochastic gradient descent. It just a little trick that we do. And another trick we can do is \n",
    "in code we also usually add a 1/n scaling factor for further convenience where <code>**ùëõ**</code> is the number of training examples or number of examples in a minibatch. This make the training numerically stable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{multline*}\n",
    "-\\dfrac{1}{n} \\sum^{n}_{i = 1} [y^{(i)} log(\\sigma(z^{(i)})) + (1 - y^{(i)})log(1 - \\sigma(z^{(i)}))]\n",
    "\\end{multline*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Doing logistic regression is similar what we have done before in Adaline, we minimized the MSE loss\n",
    "- However the difference is that in logistic regression we maximize the likelihood\n",
    "- Maximizing likelihood is the same as maximizing the log-likelihood but the latter is numerically nore stable\n",
    "- Maximizing the log likelihood is the same as minimizing the negative log likelihood which is convenient so we don't have to change our code and can still can use gradient descent (instead of gradient ascent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
